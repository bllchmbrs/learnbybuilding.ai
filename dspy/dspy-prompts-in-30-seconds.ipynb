{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e36400",
   "metadata": {},
   "source": [
    "# DSPy Prompts in 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a58f9",
   "metadata": {},
   "source": [
    "If you would rather *read* this, you can find it on [LearnByBuilding.AI](https://learnbybuilding.ai/tutorials/). This notebook only contains code, to get some prose along with it, check out the tutorial posted there.\n",
    "\n",
    "If you like this content, [follow me on twitter](https://twitter.com/bllchmbrs) for more! I'm posting all week about DSPy and providing a lot of \"hard earned\" lessons that I've gotten from learning the material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf1881-96a5-4ccb-a252-637a74d310f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cfd1b-eb5b-4311-83fa-855ed2a5e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo', max_tokens=1000)\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d242ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "Four score and seven years ago.\n",
    "Our fathers brought forth on this continent, a new nation,\n",
    "conceived in Liberty, and dedicated to the proposition\n",
    "that we could write AI prompts for the machines.\n",
    "\n",
    "Or, it would be written in python as:\n",
    "\n",
    "current_timestamp = datetime.datetime.now() - datetime.timedelta(years=7)\n",
    "def bring_forth(nation, liberty, proposition):\n",
    "    return nation, liberty, proposition\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb354628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "v1 = dspy.Predict(\"document -> summary\")\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00196e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v1.forward(document=document).summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56e0fdf",
   "metadata": {},
   "source": [
    "Ahh, it strips the new line characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7129e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.signatures import signature_to_template\n",
    "print(signature_to_template(v1.signature).query(dspy.Example(document=document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2147f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer(dspy.Signature):\n",
    "    document = dspy.InputField()\n",
    "    summary = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = dspy.Predict(Summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02329fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signature_to_template(v2.signature).query(dspy.Example(document=document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v2.forward(document=document).summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodSummarizer(dspy.Signature):\n",
    "    \"The user will give you a document, you must produce a summary of this document. Only include the summary.\"\n",
    "    document = dspy.InputField(format=lambda x: \"\\n===\\n\" + str(x) + \"\\n===\\n\")\n",
    "    summary = dspy.OutputField(format=str)\n",
    "v3 = dspy.Predict(GoodSummarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25eee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = dspy.Predict(GoodSummarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db43089",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98652d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signature_to_template(v3.signature).query(dspy.Example(document=document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba27d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = v3.forward(document=document)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8dfa2-189b-4e74-8605-327781ffef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(GrugTranslation)\n",
    "    \n",
    "    def forward(self, plain_english):\n",
    "        return self.prog(plain_english=plain_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CoT()\n",
    "c.forward(\"You should not construct complex systems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba779a",
   "metadata": {},
   "source": [
    "# Making it better, options\n",
    "\n",
    "\n",
    "1. Zero shot (no examples)\n",
    "2. Providing examples (few shot)\n",
    "3. Tuning the prompt + examples\n",
    "4. Fine tuning the model\n",
    "5. Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad4745",
   "metadata": {},
   "source": [
    "# Better examples\n",
    "\n",
    "But, what is better? How are you measuring that?\n",
    "\n",
    "Vibes to something measurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://apps.dtic.mil/sti/tr/pdf/AD0667273.pdf\n",
    "def automated_readability_index(text):\n",
    "    import re\n",
    "\n",
    "    # Count characters (ignoring whitespace)\n",
    "    characters = len(re.sub(r'\\s+', '', text))\n",
    "\n",
    "    # Count words by splitting the text\n",
    "    words = len(text.split())\n",
    "\n",
    "    # Count sentences by finding period, exclamation, or question mark\n",
    "    sentences = len(re.findall(r'[.!?\\n]', text))\n",
    "    # our change is to add a new line character as grug doesn't seem to use punctuation.\n",
    "\n",
    "    # Calculate the Automated Readability Index (ARI)\n",
    "    if words == 0 or sentences == 0:  # Prevent division by zero\n",
    "        return 0\n",
    "    \n",
    "    ari = (4.71 * (characters / words)) + (0.5 * (words / sentences)) - 21.43\n",
    "    \n",
    "    return round(ari, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in examples:\n",
    "    source_ari = automated_readability_index(ex.plain_english)\n",
    "    grug_ari = automated_readability_index(ex.grug_text)\n",
    "    print(f\"ARI {source_ari} => {grug_ari}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ea280",
   "metadata": {},
   "source": [
    "## First Metric: Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d154917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ari_metric(truth, pred, trace=None):\n",
    "    truth_grug_text = truth.grug_text\n",
    "    proposed_grug_text = pred.grug_text\n",
    "    \n",
    "    gold_ari = automated_readability_index(truth_grug_text)\n",
    "    pred_ari = automated_readability_index(proposed_grug_text)\n",
    "\n",
    "    print(f\"ARI {gold_ari} => {pred_ari}\")\n",
    "\n",
    "    ari_result = pred_ari <= 7.01\n",
    "    return ari_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbac35c",
   "metadata": {},
   "source": [
    "## Second Metric: Use a better Model to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4T = dspy.OpenAI(model='gpt-4-turbo', max_tokens=100, model_type='chat')\n",
    "\n",
    "# https://dspy-docs.vercel.app/docs/building-blocks/metrics#intermediate-using-ai-feedback-for-your-metric\n",
    "class AssessBasedOnQuestion(dspy.Signature):\n",
    "    \"\"\"Given the assessed text provide a yes or no to the assessment question.\"\"\"\n",
    "\n",
    "    assessed_text = dspy.InputField(format=str)\n",
    "    assessment_question = dspy.InputField(format=str)\n",
    "    assessment_answer = dspy.OutputField(desc=\"Yes or No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36979c76",
   "metadata": {},
   "source": [
    "Again, this is just a prompt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_question_assessment = dspy.Example(assessed_text=\"This is a test.\", assessment_question=\"Is this a test?\", assessment_answer=\"Yes\").with_inputs(\"assessed_text\", \"assessment_question\")\n",
    "print(signature_to_template(AssessBasedOnQuestion).query(example_question_assessment))\n",
    "# one note, it's technically, I believe, a `Prediction` object. But Predictions mirror example functionality:\n",
    "# https://dspy-docs.vercel.app/docs/deep-dive/signature/executing-signatures#how-predict-works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_metric(truth, pred, trace=None):\n",
    "    truth_grug_text = truth.grug_text\n",
    "    proposed_grug_text = pred.grug_text\n",
    "    similarity_question = f\"\"\"Does the assessed text have the same meaning as the gold_standard text provided?\n",
    "\n",
    "Gold Standard: \"{truth_grug_text}\"\n",
    "\n",
    "Provide only a yes or no answer.\"\"\"\n",
    "\n",
    "    with dspy.context(lm=gpt4T):\n",
    "        assessor = dspy.Predict(AssessBasedOnQuestion)\n",
    "        raw_similarity_result = assessor(assessed_text=proposed_grug_text, assessment_question=similarity_question)\n",
    "    print(raw_similarity_result)\n",
    "    raw_similarity = raw_similarity_result.assessment_answer.lower().strip()\n",
    "    same_meaning = raw_similarity == 'yes'\n",
    "    return same_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b4b14-8bc5-4ade-9ea8-f9d378c25afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_metric(provided_example, predicted, trace=None):\n",
    "    similarity = similarity_metric(provided_example, predicted, trace)\n",
    "    ari = ari_metric(provided_example, predicted, trace)\n",
    "\n",
    "    if similarity and ari:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c75c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "config = dict(max_bootstrapped_demos=4, max_labeled_demos=4)\n",
    "teleprompter = BootstrapFewShot(metric=overall_metric, **config)\n",
    "teleprompter.max_errors = 1\n",
    "optimized_cot = teleprompter.compile(CoT(), trainset=train, valset=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "individual_metrics = [similarity_metric, ari_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c591bb-81d5-48c9-8b66-c501507cabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in individual_metrics:\n",
    "    evaluate = Evaluate(metric=metric, devset=train, num_threads=1, display_progress=True, display_table=5)\n",
    "    evaluate(optimized_cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b1a68-09bf-4998-bcd7-d176d3ae3fe6",
   "metadata": {},
   "source": [
    "Follow along for subsequent tutorials on:\n",
    "\n",
    "1. Automatically optimizing prompts\n",
    "2. Customizing input to DSPy\n",
    "3. Saving prompts to use in LangChain or LlamaIndex\n",
    "4. Tuning and using open source models\n",
    "\n",
    "Cheers,\n",
    "[Bill](https://twitter.com/bllchmbrs)\n",
    "\n",
    "[Learn By Building AI](https://learnbybuilding.ai/?ref=dspy-tutorial)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b95b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cot.forward(\"You should not construct complex systems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe984271",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
