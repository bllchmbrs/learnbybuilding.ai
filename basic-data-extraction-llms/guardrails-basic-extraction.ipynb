{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc5b8de-c56b-4104-95df-dc9246883705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c40f04-4407-45f8-9985-b159c13ad7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guardrails-ai==0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep guardrails-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb484c3-41ae-477b-b53f-8cda908428f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.9\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b965611-0a5d-4004-b62d-0af1221a03d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b85a7dc3-15f8-46b6-870f-8f87ae56c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><em>Thanks to the </em><em>over 11,000 people</em><em> who joined us for the first AI Engineer Su\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "podcast_atom_link = \"https://api.substack.com/feed/podcast/1084089.rss\" # latent space podcastbbbbb\n",
    "parsed = feedparser.parse(podcast_atom_link)\n",
    "episode = [ep for ep in parsed.entries if ep['title'] == \"Why AI Agents Don't Work (yet) - with Kanjun Qiu of Imbue\"][0]\n",
    "episode_summary = episode['summary']\n",
    "print(episode_summary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2af4fc2-6085-45b4-935f-e67f71f24450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of the transcript: 58\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "\n",
    "parsed_summary = partition_html(text=''.join(episode_summary)) \n",
    "start_of_transcript = [x.text for x in parsed_summary].index(\"Transcript\") + 1\n",
    "print(f\"First line of the transcript: {start_of_transcript}\")\n",
    "text = '\\n'.join(t.text for t in parsed_summary[start_of_transcript:])\n",
    "text = text[:3508] # shortening the transcript for speed & cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8c993-f77f-4f5e-86cc-550665950f2f",
   "metadata": {},
   "source": [
    "## Using Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8c469a-b16a-451f-9818-db889d98166c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "from pydantic import Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    school: Optional[str] = Field(..., description=\"The school this person attended\")\n",
    "    company: Optional[str] = Field(..., description=\"The company this person works for\")\n",
    "\n",
    "class People(BaseModel):\n",
    "    people: List[Person]\n",
    "\n",
    "guard = gd.Guard.from_pydantic(output_class=People, prompt=\"Get the following objects from the text:\\n\\n ${text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f02712c-3bdc-449f-84b6-e60aa2954f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'name': 'Alessio', 'school': 'Residence at Decibel Partners', 'company': 'CTO'}, {'name': 'Swyx', 'school': 'Smol.ai', 'company': 'founder'}, {'name': 'Kanjun', 'school': 'Imbue', 'company': 'founder'}]}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "raw_llm_output, validated_output = guard(\n",
    "    openai.ChatCompletion.create,\n",
    "    prompt_params={\"text\": text},\n",
    ")\n",
    "\n",
    "print(validated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0ef84d-7dd3-4220-af91-4f1f8826654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamchambers/miniconda3/envs/guardrails-extract/lib/python3.9/site-packages/guardrails/prompt/instructions.py:32: UserWarning: Instructions do not have any variables, if you are migrating follow the new variable convention documented here: https://docs.getguardrails.ai/0-2-migration/\n",
      "  warn(\n",
      "/Users/williamchambers/miniconda3/envs/guardrails-extract/lib/python3.9/site-packages/guardrails/prompt/prompt.py:23: UserWarning: Prompt does not have any variables, if you are migrating follow the new variable convention documented here: https://docs.getguardrails.ai/0-2-migration/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect_value={'people': [{'name': 'Alessio', 'school': 'Decibel Partners', 'company': 'CTO'}, {'name': 'Swyx', 'school': 'Smol.ai', 'company': 'founder'}, {'name': 'Kanjun', 'school': 'Imbue', 'company': 'founder'}], 'companies': [{'name': 'Decibel Partners'}, {'name': 'Residence'}, {'name': 'Smol.ai'}, {'name': 'Imbue'}]} fail_results=[FailResult(outcome='fail', metadata=None, error_message='JSON does not match schema', fix_value=None)]\n"
     ]
    }
   ],
   "source": [
    "class Company(BaseModel):\n",
    "    name:str\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    paper_name:str = Field(..., description=\"an academic paper reference discussed\")\n",
    "    \n",
    "class ExtractedInfo(BaseModel):\n",
    "    people: List[Person]\n",
    "    companies: List[Company]\n",
    "    research_papers: Optional[List[ResearchPaper]]\n",
    "\n",
    "guard = gd.Guard.from_pydantic(output_class=ExtractedInfo, prompt=\"Get the following objects from the text:\\n\\n ${text}\")\n",
    "raw_llm_output, validated_output = guard(\n",
    "    openai.ChatCompletion.create,\n",
    "    prompt_params={\"text\": text},\n",
    ")\n",
    "\n",
    "print(validated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192865a-7fce-4ceb-b659-90f393a2d39a",
   "metadata": {},
   "source": [
    "**Note:** The result failed to parse, while the other two libraries succeeded just fine. It might be in the implementation or might be a bug in this version, but it didn't work out of the box."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
