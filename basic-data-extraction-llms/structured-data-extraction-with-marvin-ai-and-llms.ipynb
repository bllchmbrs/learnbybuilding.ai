{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a6bcf0-6627-45f6-8ad4-93a2cf3a7d21",
   "metadata": {},
   "source": [
    "# Structured Data Extraction using LLMs and Marvin AI \n",
    "\n",
    "In this post, we're going to be extracting structured data from a podcast transcript. We've all seen the ability for generative models to be effective *generating* text.\n",
    "\n",
    "**But what about extracting data?**\n",
    "\n",
    "Data extraction is a far more common use case (today) than generation, in particular for businesses. Businesses have to process all kinds of documents, exchange them and so on.\n",
    "\n",
    "**Emerging Use Case: LLMs for data extraction**\n",
    "\n",
    "If you think about it, summarization is effectively data extraction. We've seen LLMs perform well at summarization, but did you know that they can extract structured data quite well?\n",
    "\n",
    "## What you'll learn from this post\n",
    "\n",
    "In this post, you'll learn how to extract structured data from LLMs into Pydantic objects using the [Marvin AI](https://www.askmarvin.ai/welcome/what_is_marvin/) library.\n",
    "\n",
    "## Here's us setting up on environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e94783-c712-4f84-aa14-b5e15fe7fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aedeafbd-2dd5-4f65-bc59-fa5a59556fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.2\n",
      "1.5.5\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.__version__)\n",
    "import marvin\n",
    "print(marvin.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee2405c-8a21-41b1-b38d-63f242f3fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b0d46-cee5-41b8-b5c6-bce0ba1f160f",
   "metadata": {},
   "source": [
    "## Background on Marvin\n",
    "\n",
    "![Ask Marvin AI](https://images.learnbybuilding.ai/marvin-ai-screenshot.webp)\n",
    "\n",
    "Marvin, as a library, has larger ambitions than just a data extraction library. In the creators' words,\n",
    "\n",
    "> Marvin is a lightweight AI engineering framework for building natural language interfaces that are reliable, scalable, and easy to trust.\n",
    "> \n",
    "> Sometimes the most challenging part of working with generative AI is remembering that it's not magic; it's software. It's new, it's nondeterministic, and it's incredibly powerful - but still software.\n",
    "> \n",
    "> Marvin's goal is to bring the best practices for building dependable, observable software to generative AI. As the team behind [Prefect](https://www.prefect.io/), which does something very similar for data engineers, we've poured years of open-source developer tool experience and lessons into Marvin's design.\n",
    "\n",
    "At the time of this writing, [Marvin](https://www.askmarvin.ai/), has a growing discord, is version 1.5.5 (and therefore ready for production). It also has the highest github stars of our contenders as well as the most forks.\n",
    "\n",
    "Marvin is commercially backed by [Prefect](https://www.prefect.io/).\n",
    "\n",
    "\n",
    "Overall, Marvin is a fairly simple feeling library. You'll see that below.\n",
    "\n",
    "Let's get started with the tutorial.\n",
    "\n",
    "\n",
    "## Pre-processing the data\n",
    "\n",
    "Here, we are fetching and parsing an RSS feed from a podcast. We specifically target an episode by its title and then retrieve its summary from the podcast description. This is similar to a [tutorial on llamaindex](https://learnbybuilding.ai/tutorials/rag-chatbot-on-podcast-llamaindex-faiss-openai) that we recently published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dadfb61b-79ea-4531-a7a0-903c9acd591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><em>Thanks to the </em><em>over 11,000 people</em><em> who joined us for the first AI Engineer Su\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "podcast_atom_link = \"https://api.substack.com/feed/podcast/1084089.rss\" # latent space podcastbbbbb\n",
    "parsed = feedparser.parse(podcast_atom_link)\n",
    "episode = [ep for ep in parsed.entries if ep['title'] == \"Why AI Agents Don't Work (yet) - with Kanjun Qiu of Imbue\"][0]\n",
    "episode_summary = episode['summary']\n",
    "print(episode_summary[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed1548-3e6d-42dc-b51e-9c546cba50a2",
   "metadata": {},
   "source": [
    "Now we're going to extract the shortened episode summary. We'll also shorten the summary just to speed up our extraction. In the future, we can extend the transcript to cover the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2af4fc2-6085-45b4-935f-e67f71f24450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of the transcript: 58\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "\n",
    "parsed_summary = partition_html(text=''.join(episode_summary)) \n",
    "start_of_transcript = [x.text for x in parsed_summary].index(\"Transcript\") + 1\n",
    "print(f\"First line of the transcript: {start_of_transcript}\")\n",
    "text = '\\n'.join(t.text for t in parsed_summary[start_of_transcript:])\n",
    "text = text[:3508] # shortening the transcript for speed & cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cea930-f3ff-4a35-aa14-f52bdb304229",
   "metadata": {},
   "source": [
    "## Using Marvin\n",
    "\n",
    "The first step is to define our pydantic models. You'll notice that we [use Python Decorators](https://realpython.com/primer-on-python-decorators/) the actual class that we'll be classing with `@ai_model`. This allows us to call this class directly on our data.\n",
    "\n",
    "This is a key aspect of the user experience of Marvin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966ce411-c2b4-4adf-9917-8c1b4391bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin import ai_model\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "from pydantic import Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    school: Optional[str] = Field(..., description=\"The school this person attended\")\n",
    "    company: Optional[str] = Field(..., description=\"The company this person works for\")\n",
    "\n",
    "@ai_model\n",
    "class People(BaseModel):\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0862a-30f7-461b-99dd-62edd62df5aa",
   "metadata": {},
   "source": [
    "Once we do that, we simply call our function on the input data. Simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27663614-45b4-4c2f-a59f-37a5f0945d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Alessio', school=None, company='Residence at Decibel Partners'), Person(name='Swyx', school=None, company='Smol.ai'), Person(name='Kanjun', school='MIT', company='Imbue')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "People(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299adf2-59d4-48a2-a388-7137dd25dc68",
   "metadata": {},
   "source": [
    "Now that we've extracted the people from the podcast, we can make things a bit more complicated.\n",
    "\n",
    "Let's try to extract not just people but also the companies mentioned as well as any research papers mentioned.\n",
    "\n",
    "This hints at some of the power of large language models, we're taking unstructured text and turning it into JSON objects (well, pydantic objects, but that's no problem) that we can use in down stream pipelines. This is an extremely powerful tool to have in our tool belt.\n",
    "\n",
    "Let's see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2644ac60-27bd-4998-acac-ae19d8c5e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Company(BaseModel):\n",
    "    name:str\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    paper_name:str = Field(..., description=\"an academic paper reference discussed\")\n",
    "\n",
    "@ai_model(instructions=\"Get the following information from the text\")\n",
    "class ExtractedInfo(BaseModel):\n",
    "    people: List[Person]\n",
    "    companies: List[Company]\n",
    "    research_papers: Optional[List[ResearchPaper]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ee0c4-62fb-4e3e-ba85-fe5534edbe51",
   "metadata": {},
   "source": [
    "Once we do that, we simply call our function on the input data. Simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6d2a39-20e8-4a21-9425-6100947b1893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractedInfo(people=[Person(name='Alessio', school=None, company='Residence at Decibel Partners'), Person(name='Swyx', school=None, company='Smol.ai'), Person(name='Kanjun', school='MIT', company='Imbue')], companies=[Company(name='Decibel Partners'), Company(name='Smol.ai'), Company(name='Imbue'), Company(name='Generally Intelligent'), Company(name='Ember'), Company(name='Sorceress')], research_papers=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractedInfo(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb672308-2188-4515-8c9a-326e15200b10",
   "metadata": {},
   "source": [
    "Overall, it did a great job! We got some good results!\n",
    "\n",
    "\n",
    "**Note**: What's interesting is that if you don't supply the `instructions` you won't get as strong of results. I started off with `instructions` blank and got poor results. When I did the same with instructor, it worked fine.\n",
    "\n",
    "Changing the decorator instructions gave me better results. This is also allows you to [configure th LLM](https://www.askmarvin.ai/components/ai_model/#configuring-the-llm) as well as temperature and more.\n",
    "\n",
    "\n",
    "## Wrapping it all up\n",
    "\n",
    "The sky is really the limit here. There's so much structured data that's been locked up in unstructured text. I'm bullish on this space and can't wait to see what you build with this tool!\n",
    "\n",
    "If you found this interesting, you might want to see similar posts on:\n",
    "1. [Comparing 3 Data Extraction Libraries: Marvin, Instructor, and Guardrails](https://learnbybuilding.ai/vs/marvin-ai-vs-guardrails-vs-instructor)\n",
    "2. [Structured Data Extraction using LLMs and Instructor](https://learnbybuilding.ai/tutorials/structured-data-extraction-with-instructor-and-llms)\n",
    "3. [Structured Data Extraction using LLMs and Guardrails AI](https://learnbybuilding.ai/tutorials/structured-data-extraction-with-guardrails-and-llms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
