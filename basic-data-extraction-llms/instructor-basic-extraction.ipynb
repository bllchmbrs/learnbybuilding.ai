{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eae8c64-ee1c-4990-b8f7-13b052844cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3eabca-c34f-4027-85e8-6470c64bda42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instructor==0.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14884fa-50ea-4c8c-bacc-0782a9b6ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.2\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee2405c-8a21-41b1-b38d-63f242f3fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6d064d-0f75-4b9e-a610-955ea43e1675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><em>Thanks to the </em><em>over 11,000 people</em><em> who joined us for the first AI Engineer Su\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "podcast_atom_link = \"https://api.substack.com/feed/podcast/1084089.rss\" # latent space podcastbbbbb\n",
    "parsed = feedparser.parse(podcast_atom_link)\n",
    "episode = [ep for ep in parsed.entries if ep['title'] == \"Why AI Agents Don't Work (yet) - with Kanjun Qiu of Imbue\"][0]\n",
    "episode_summary = episode['summary']\n",
    "print(episode_summary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2af4fc2-6085-45b4-935f-e67f71f24450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of the transcript: 58\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "\n",
    "parsed_summary = partition_html(text=''.join(episode_summary)) \n",
    "start_of_transcript = [x.text for x in parsed_summary].index(\"Transcript\") + 1\n",
    "print(f\"First line of the transcript: {start_of_transcript}\")\n",
    "text = '\\n'.join(t.text for t in parsed_summary[start_of_transcript:])\n",
    "text = text[:3508] # shortening the transcript for speed & cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0efc7-1cfe-4733-be98-40b34b11189b",
   "metadata": {},
   "source": [
    "## Using Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff585fc-17f2-480c-81e3-f2123676a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "from pydantic import Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    school: Optional[str] = Field(..., description=\"The school this person attended\")\n",
    "    company: Optional[str] = Field(..., description=\"The company this person works for \")\n",
    "\n",
    "class People(BaseModel):\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a3949e-e276-4576-8eaf-38fc97af5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import instructor\n",
    "\n",
    "instructor.patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2523c901-a899-4c64-b04b-8bbd210a1cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='Alessio', school=None, company='Decibel Partners'), Person(name='Swyx', school=None, company='Smol.ai'), Person(name='Kanjun', school='MIT', company='Imbue'), Person(name='Josh', school=None, company='Imbue')]\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    response_model=People,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335844c-f84b-42c5-af8a-fa32652ccc06",
   "metadata": {},
   "source": [
    "Overall the result is high quality, we've gotten all the names and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196ab8ea-d16f-40bd-b243-859440588790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='Alessio', school=None, company='Decibel Partners'), Person(name='Swyx', school=None, company='Smol.ai'), Person(name='Kanjun', school='MIT', company='Imbue'), Person(name='Josh', school=None, company='Ember')] companies=[Company(name='Decibel Partners'), Company(name='Smol.ai'), Company(name='Imbue'), Company(name='Generally Intelligent'), Company(name='Ember'), Company(name='Sorceress'), Company(name='Dropbox'), Company(name='MIT Media Lab'), Company(name='OpenA')] research_papers=None\n"
     ]
    }
   ],
   "source": [
    "class Company(BaseModel):\n",
    "    name:str\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    paper_name:str = Field(..., description=\"an academic paper reference discussed\")\n",
    "    \n",
    "class ExtractedInfo(BaseModel):\n",
    "    people: List[Person]\n",
    "    companies: List[Company]\n",
    "    research_papers: Optional[List[ResearchPaper]]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    response_model=ExtractedInfo,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5484bb8-343e-4696-8867-bc9416fe5c6a",
   "metadata": {},
   "source": [
    "You can see how well this works, to grab a whole bunch of structured data for us with basically no work. Right now we're just working on a excerpt of this data, but with basically zero NLP specific work, we're able to get some pretty powerful results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
