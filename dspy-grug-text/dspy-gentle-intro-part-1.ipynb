{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e36400",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to [DSPy](https://dspy-docs.vercel.app/)\n",
    "For grug brained developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a58f9",
   "metadata": {},
   "source": [
    "If you would rather *read* this, you can find it on [LearnByBuilding.AI](https://learnbybuilding.ai/tutorials/). This notebook only contains code, to get some prose along with it, check out the tutorial posted there.\n",
    "\n",
    "If you like this content, [follow me on twitter](https://twitter.com/bllchmbrs) for more! I'm posting all week about DSPy and providing a lot of \"hard earned\" lessons that I've gotten from learning the material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bf1881-96a5-4ccb-a252-637a74d310f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738cfd1b-eb5b-4311-83fa-855ed2a5e83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamchambers/miniconda3/envs/lbb/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2024-04-23 10:37:56.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlab\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mLoading environment variables\u001b[0m\n",
      "\u001b[32m2024-04-23 10:37:56.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlab\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mEnvironment variables loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c30f1e4-b3af-4044-b2ba-a2f6f86b10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res = requests.get(\"https://grugbrain.dev/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b25187",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "raw_text = [p.text for p in soup.find_all('p') if p.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b18c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this collection of thoughts on software development gathered by grug brain developer',\n",
       " 'grug brain developer not so smart, but grug brain developer program many long year and learn some things\\nalthough mostly still confused',\n",
       " 'grug brain developer try collect learns into small, easily digestible and funny page, not only for you, the young grug, but also for him\\nbecause as grug brain developer get older he forget important things, like what had for breakfast or if put pants on',\n",
       " 'big brained developers are many, and some not expected to like this, make sour face',\n",
       " 'THINK they are big brained developers many, many more, and more even definitely probably maybe not like this, many\\nsour face (such is internet)',\n",
       " '(note: grug once think big brained but learn hard way)',\n",
       " 'is fine!',\n",
       " 'is free country sort of and end of day not really matter too much, but grug hope you fun reading and maybe learn from\\nmany, many mistake grug make over long program life',\n",
       " 'apex predator of grug is complexity',\n",
       " 'complexity bad']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e62629-ce0a-4302-88c9-4eb3af35cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "openai_model_name= \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e675ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildMessages:\n",
    "    def __init__(self, system_prompt, user_prompt):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.user_prompt = user_prompt\n",
    "\n",
    "    def render(self, **kwargs):\n",
    "        sys = self.system_prompt.format(**kwargs)\n",
    "        user = self.user_prompt.format(**kwargs)\n",
    "\n",
    "        return [\n",
    "            {\"role\":\"system\", \"content\":sys},\n",
    "            {\"role\":\"user\", \"content\":user},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf655143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "@cache\n",
    "def translate_grug(grug_text):\n",
    "    prompt = BuildMessages(\n",
    "    \"You are an expert in deciphering strange text. The user will provide text written by someone named Grug and you will provide the translation.\",\n",
    "    \"Translate the following text into plain english: {text}. Do not respond with any other text. Only provide that text. Now take a deep breath and begin.\"\n",
    ")\n",
    "    result = client.chat.completions.create(messages=prompt.render(text=grug_text), model=openai_model_name)\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc25a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grug is a software developer who has gathered a collection of thoughts on software development.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_grug(raw_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93bd5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for grug_text in raw_text[:10]:\n",
    "    translated = translate_grug(grug_text)\n",
    "    dataset.append({\"grug_text\":grug_text, \"plain_english\":translated})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e71018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0985f0",
   "metadata": {},
   "source": [
    "# Building a Dataset\n",
    "\n",
    "\n",
    "Or, more simply, using `dspy.Example`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ede8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for row in dataset:\n",
    "    examples.append(dspy.Example(grug_text=row[\"grug_text\"], plain_english=row[\"plain_english\"]).with_inputs(\"plain_english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e019eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_for_train_test(values, test_size = 1/3.0):\n",
    "    np.random.shuffle(values)\n",
    "    train = int(len(values)-test_size*len(values))\n",
    "    print(train)\n",
    "    return values[:train], values[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a03c608-dcce-4c06-aa94-a244bbcfe797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "train, test = split_for_train_test(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f549811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'grug_text': 'big brained developers are many, and some not expected to like this, make sour face', 'plain_english': 'Smart developers are plentiful, and some may not be happy about this, resulting in displeased expressions.'}) (input_keys={'plain_english'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea4298e0-657c-4341-b8e3-616ba791e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo', max_tokens=1000)\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c18c2",
   "metadata": {},
   "source": [
    "# Prompts... I mean Signatures\n",
    "\n",
    "Note, not really optimized for chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e684e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrugTranslation(dspy.Signature):\n",
    "    \"Translate plain english to Grug text.\"\n",
    "    plain_english = dspy.InputField()\n",
    "    grug_text = dspy.OutputField()\n",
    "    # grug_text = dspy.OutputField(prefix=\"The Grug Text:\", format=lambda x: \"===\" + str(x) + \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dba27d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plain_english -> grug_text'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrugTranslation.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "408a329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SignatureMeta.with_instructions of GrugTranslation(plain_english -> grug_text\n",
       "    instructions='Translate plain english to Grug text.'\n",
       "    plain_english = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Plain English:', 'desc': '${plain_english}'})\n",
       "    grug_text = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Grug Text:', 'desc': '${grug_text}'})\n",
       ")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrugTranslation.with_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbdd480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template(Translate plain english to Grug text., ['Plain English:', 'Grug Text:'])\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/stanfordnlp/dspy/blob/1c10a9d476737533a53d6bee62c234e375eb8fcb/dsp/templates/template_v3.py#L22\n",
    "from dspy.signatures.signature import signature_to_template\n",
    "grug_translation_as_template = signature_to_template(GrugTranslation)\n",
    "print(str(grug_translation_as_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e8b486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain English: Smart developers are plentiful, and some may not be happy about this, resulting in displeased expressions.\n",
      "Grug Text: big brained developers are many, and some not expected to like this, make sour face\n"
     ]
    }
   ],
   "source": [
    "print(grug_translation_as_template.query(examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef642d30",
   "metadata": {},
   "source": [
    "# Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5d8dfa2-189b-4e74-8605-327781ffef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(GrugTranslation)\n",
    "    \n",
    "    def forward(self, plain_english):\n",
    "        return self.prog(plain_english=plain_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "057a1de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='produce the grug_text. We need to simplify and avoid creating intricate structures.',\n",
       "    grug_text='Grug no make big big thing.'\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = CoT()\n",
    "c.forward(\"You should not construct complex systems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba779a",
   "metadata": {},
   "source": [
    "# Making it better, options\n",
    "\n",
    "\n",
    "1. Zero shot (no examples)\n",
    "2. Providing examples (few shot)\n",
    "3. Tuning the prompt + examples\n",
    "4. Fine tuning the model\n",
    "5. Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad4745",
   "metadata": {},
   "source": [
    "# Better examples\n",
    "\n",
    "But, what is better? How are you measuring that?\n",
    "\n",
    "Vibes to something measurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dc6b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://apps.dtic.mil/sti/tr/pdf/AD0667273.pdf\n",
    "def automated_readability_index(text):\n",
    "    import re\n",
    "\n",
    "    # Count characters (ignoring whitespace)\n",
    "    characters = len(re.sub(r'\\s+', '', text))\n",
    "\n",
    "    # Count words by splitting the text\n",
    "    words = len(text.split())\n",
    "\n",
    "    # Count sentences by finding period, exclamation, or question mark\n",
    "    sentences = len(re.findall(r'[.!?\\n]', text))\n",
    "    # our change is to add a new line character as grug doesn't seem to use punctuation.\n",
    "\n",
    "    # Calculate the Automated Readability Index (ARI)\n",
    "    if words == 0 or sentences == 0:  # Prevent division by zero\n",
    "        return 0\n",
    "    \n",
    "    ari = (4.71 * (characters / words)) + (0.5 * (words / sentences)) - 21.43\n",
    "    \n",
    "    return round(ari, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e0e5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 13.36 => 0\n",
      "ARI 10.8 => 13.98\n",
      "ARI 7.2 => 0\n",
      "ARI 8.54 => 14.12\n",
      "ARI 8.82 => 14.62\n",
      "ARI 11.5 => 0\n",
      "ARI 8.0 => 22.95\n",
      "ARI 7.64 => 0\n",
      "ARI -3.95 => -3.95\n",
      "ARI 5.19 => 0\n"
     ]
    }
   ],
   "source": [
    "for ex in examples:\n",
    "    source_ari = automated_readability_index(ex.plain_english)\n",
    "    grug_ari = automated_readability_index(ex.grug_text)\n",
    "    print(f\"ARI {source_ari} => {grug_ari}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ea280",
   "metadata": {},
   "source": [
    "## First Metric: Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d154917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ari_metric(truth, pred, trace=None):\n",
    "    truth_grug_text = truth.grug_text\n",
    "    proposed_grug_text = pred.grug_text\n",
    "    \n",
    "    gold_ari = automated_readability_index(truth_grug_text)\n",
    "    pred_ari = automated_readability_index(proposed_grug_text)\n",
    "\n",
    "    print(f\"ARI {gold_ari} => {pred_ari}\")\n",
    "\n",
    "    ari_result = pred_ari <= 7.01\n",
    "    return ari_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbac35c",
   "metadata": {},
   "source": [
    "## Second Metric: Use a better Model to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9af7c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4T = dspy.OpenAI(model='gpt-4-turbo', max_tokens=100, model_type='chat')\n",
    "\n",
    "# https://dspy-docs.vercel.app/docs/building-blocks/metrics#intermediate-using-ai-feedback-for-your-metric\n",
    "class AssessBasedOnQuestion(dspy.Signature):\n",
    "    \"\"\"Given the assessed text provide a yes or no to the assessment question.\"\"\"\n",
    "\n",
    "    assessed_text = dspy.InputField(format=str)\n",
    "    assessment_question = dspy.InputField(format=str)\n",
    "    assessment_answer = dspy.OutputField(desc=\"Yes or No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36979c76",
   "metadata": {},
   "source": [
    "Again, this is just a prompt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a078a62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessed Text: This is a test.\n",
      "Assessment Question: Is this a test?\n",
      "Assessment Answer: Yes\n"
     ]
    }
   ],
   "source": [
    "example_question_assessment = dspy.Example(assessed_text=\"This is a test.\", assessment_question=\"Is this a test?\", assessment_answer=\"Yes\").with_inputs(\"assessed_text\", \"assessment_question\")\n",
    "print(signature_to_template(AssessBasedOnQuestion).query(example_question_assessment))\n",
    "# one note, it's technically, I believe, a `Prediction` object. But Predictions mirror example functionality:\n",
    "# https://dspy-docs.vercel.app/docs/deep-dive/signature/executing-signatures#how-predict-works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d20ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_metric(truth, pred, trace=None):\n",
    "    truth_grug_text = truth.grug_text\n",
    "    proposed_grug_text = pred.grug_text\n",
    "    similarity_question = f\"\"\"Does the assessed text have the same meaning as the gold_standard text provided?\n",
    "\n",
    "Gold Standard: \"{truth_grug_text}\"\n",
    "\n",
    "Provide only a yes or no answer.\"\"\"\n",
    "\n",
    "    with dspy.context(lm=gpt4T):\n",
    "        assessor = dspy.Predict(AssessBasedOnQuestion)\n",
    "        raw_similarity_result = assessor(assessed_text=proposed_grug_text, assessment_question=similarity_question)\n",
    "    print(raw_similarity_result)\n",
    "    raw_similarity = raw_similarity_result.assessment_answer.lower().strip()\n",
    "    same_meaning = raw_similarity == 'yes'\n",
    "    return same_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "863b4b14-8bc5-4ade-9ea8-f9d378c25afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_metric(provided_example, predicted, trace=None):\n",
    "    similarity = similarity_metric(provided_example, predicted, trace)\n",
    "    ari = ari_metric(provided_example, predicted, trace)\n",
    "\n",
    "    if similarity and ari:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55c75c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:12,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n",
      "ARI 0 => 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:04<00:09,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n",
      "ARI 13.98 => 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:06<00:06,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n",
      "ARI 0 => 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:10<00:05,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Assessment Answer: Yes'\n",
      ")\n",
      "ARI 14.12 => 5.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n",
      "ARI 14.62 => 6.08\n",
      "Bootstrapped 4 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "config = dict(max_bootstrapped_demos=4, max_labeled_demos=4)\n",
    "teleprompter = BootstrapFewShot(metric=overall_metric, **config)\n",
    "teleprompter.max_errors = 1\n",
    "optimized_cot = teleprompter.compile(CoT(), trainset=train, valset=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a9bda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "individual_metrics = [similarity_metric, ari_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7c591bb-81d5-48c9-8b66-c501507cabea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):  17%|█▋        | 1/6 [00:01<00:06,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):  33%|███▎      | 2/6 [00:02<00:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 3  (100.0):  50%|█████     | 3/6 [00:03<00:03,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 4  (75.0):  67%|██████▋   | 4/6 [00:06<00:03,  1.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Assessment Answer: No'\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 5  (80.0):  83%|████████▎ | 5/6 [00:08<00:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='Yes'\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 6  (66.7): 100%|██████████| 6/6 [00:09<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    assessment_answer='No'\n",
      ")\n",
      "Average Metric: 4 / 6  (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6127c th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6127c td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6127c_row0_col0, #T_6127c_row0_col1, #T_6127c_row0_col2, #T_6127c_row0_col3, #T_6127c_row0_col4, #T_6127c_row1_col0, #T_6127c_row1_col1, #T_6127c_row1_col2, #T_6127c_row1_col3, #T_6127c_row1_col4, #T_6127c_row2_col0, #T_6127c_row2_col1, #T_6127c_row2_col2, #T_6127c_row2_col3, #T_6127c_row2_col4, #T_6127c_row3_col0, #T_6127c_row3_col1, #T_6127c_row3_col2, #T_6127c_row3_col3, #T_6127c_row3_col4, #T_6127c_row4_col0, #T_6127c_row4_col1, #T_6127c_row4_col2, #T_6127c_row4_col3, #T_6127c_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6127c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6127c_level0_col0\" class=\"col_heading level0 col0\" >example_grug_text</th>\n",
       "      <th id=\"T_6127c_level0_col1\" class=\"col_heading level0 col1\" >plain_english</th>\n",
       "      <th id=\"T_6127c_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_6127c_level0_col3\" class=\"col_heading level0 col3\" >pred_grug_text</th>\n",
       "      <th id=\"T_6127c_level0_col4\" class=\"col_heading level0 col4\" >similarity_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6127c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6127c_row0_col0\" class=\"data row0 col0\" >big brained developers are many, and some not expected to like this, make sour face</td>\n",
       "      <td id=\"T_6127c_row0_col1\" class=\"data row0 col1\" >Smart developers are plentiful, and some may not be happy about this, resulting in displeased expressions.</td>\n",
       "      <td id=\"T_6127c_row0_col2\" class=\"data row0 col2\" >produce the grug_text. We will break down the idea of smart developers being plentiful and some not being happy about it, leading to displeased expressions.</td>\n",
       "      <td id=\"T_6127c_row0_col3\" class=\"data row0 col3\" >many smart developers, some not happy, make face not pleased</td>\n",
       "      <td id=\"T_6127c_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6127c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6127c_row1_col0\" class=\"data row1 col0\" >grug brain developer not so smart, but grug brain developer program many long year and learn some things\n",
       "although mostly still confused</td>\n",
       "      <td id=\"T_6127c_row1_col1\" class=\"data row1 col1\" >Grug, a brain developer, is not very intelligent. However, Grug has been developing programs for many years and has learned a few things, although still...</td>\n",
       "      <td id=\"T_6127c_row1_col2\" class=\"data row1 col2\" >produce the grug_text. We will simplify the idea of Grug being a brain developer who is not very intelligent but has been developing programs for...</td>\n",
       "      <td id=\"T_6127c_row1_col3\" class=\"data row1 col3\" >grug brain developer not very big brain, but many years program develop and learn some things, still mostly confused feeling</td>\n",
       "      <td id=\"T_6127c_row1_col4\" class=\"data row1 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6127c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6127c_row2_col0\" class=\"data row2 col0\" >(note: grug once think big brained but learn hard way)</td>\n",
       "      <td id=\"T_6127c_row2_col1\" class=\"data row2 col1\" >Grug once thought he was very intelligent, but then he learned the hard way that he was not.</td>\n",
       "      <td id=\"T_6127c_row2_col2\" class=\"data row2 col2\" >realize that Grug's intelligence is not as high as he thought. We...</td>\n",
       "      <td id=\"T_6127c_row2_col3\" class=\"data row2 col3\" >grug think big brain once, but then learn hard way not big brain</td>\n",
       "      <td id=\"T_6127c_row2_col4\" class=\"data row2 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6127c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6127c_row3_col0\" class=\"data row3 col0\" >THINK they are big brained developers many, many more, and more even definitely probably maybe not like this, many\n",
       "sour face (such is internet)</td>\n",
       "      <td id=\"T_6127c_row3_col1\" class=\"data row3 col1\" >Grug believes there are many developers who think they are very intelligent, and even more than that, but in reality, there may not be many...</td>\n",
       "      <td id=\"T_6127c_row3_col2\" class=\"data row3 col2\" >produce the grug_text. We will simplify the idea of developers thinking they are smart and the reality of it, along with the negativity of the...</td>\n",
       "      <td id=\"T_6127c_row3_col3\" class=\"data row3 col3\" >grug think many developers big brain, even more than that, but maybe not many like that. internet negative place.</td>\n",
       "      <td id=\"T_6127c_row3_col4\" class=\"data row3 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6127c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6127c_row4_col0\" class=\"data row4 col0\" >is free country sort of and end of day not really matter too much, but grug hope you fun reading and maybe learn from many,...</td>\n",
       "      <td id=\"T_6127c_row4_col1\" class=\"data row4 col1\" >This is a free country of sorts and in the end of the day, it doesn't really matter too much. But Grug hopes you have...</td>\n",
       "      <td id=\"T_6127c_row4_col2\" class=\"data row4 col2\" >produce the grug_text. We will simplify the idea of a free country and the importance of having fun and learning from mistakes in Grug language.</td>\n",
       "      <td id=\"T_6127c_row4_col3\" class=\"data row4 col3\" >free country kind of, end of day not matter much. grug hope fun read and maybe learn from many, many mistake grug make long programming...</td>\n",
       "      <td id=\"T_6127c_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12f029510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 6  (83.3): 100%|██████████| 6/6 [00:00<00:00, 550.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0 => 0\n",
      "ARI 13.98 => 0\n",
      "ARI 0 => 0\n",
      "ARI 14.12 => 6.87\n",
      "ARI 14.62 => 6.08\n",
      "ARI 0 => 15.52\n",
      "Average Metric: 5 / 6  (83.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_415cc th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_415cc td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_415cc_row0_col0, #T_415cc_row0_col1, #T_415cc_row0_col2, #T_415cc_row0_col3, #T_415cc_row0_col4, #T_415cc_row1_col0, #T_415cc_row1_col1, #T_415cc_row1_col2, #T_415cc_row1_col3, #T_415cc_row1_col4, #T_415cc_row2_col0, #T_415cc_row2_col1, #T_415cc_row2_col2, #T_415cc_row2_col3, #T_415cc_row2_col4, #T_415cc_row3_col0, #T_415cc_row3_col1, #T_415cc_row3_col2, #T_415cc_row3_col3, #T_415cc_row3_col4, #T_415cc_row4_col0, #T_415cc_row4_col1, #T_415cc_row4_col2, #T_415cc_row4_col3, #T_415cc_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_415cc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_415cc_level0_col0\" class=\"col_heading level0 col0\" >example_grug_text</th>\n",
       "      <th id=\"T_415cc_level0_col1\" class=\"col_heading level0 col1\" >plain_english</th>\n",
       "      <th id=\"T_415cc_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_415cc_level0_col3\" class=\"col_heading level0 col3\" >pred_grug_text</th>\n",
       "      <th id=\"T_415cc_level0_col4\" class=\"col_heading level0 col4\" >ari_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_415cc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_415cc_row0_col0\" class=\"data row0 col0\" >big brained developers are many, and some not expected to like this, make sour face</td>\n",
       "      <td id=\"T_415cc_row0_col1\" class=\"data row0 col1\" >Smart developers are plentiful, and some may not be happy about this, resulting in displeased expressions.</td>\n",
       "      <td id=\"T_415cc_row0_col2\" class=\"data row0 col2\" >produce the grug_text. We will break down the idea of smart developers being plentiful and some not being happy about it, leading to displeased expressions.</td>\n",
       "      <td id=\"T_415cc_row0_col3\" class=\"data row0 col3\" >many smart developers, some not happy, make face not pleased</td>\n",
       "      <td id=\"T_415cc_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_415cc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_415cc_row1_col0\" class=\"data row1 col0\" >grug brain developer not so smart, but grug brain developer program many long year and learn some things\n",
       "although mostly still confused</td>\n",
       "      <td id=\"T_415cc_row1_col1\" class=\"data row1 col1\" >Grug, a brain developer, is not very intelligent. However, Grug has been developing programs for many years and has learned a few things, although still...</td>\n",
       "      <td id=\"T_415cc_row1_col2\" class=\"data row1 col2\" >produce the grug_text. We will simplify the idea of Grug being a brain developer who is not very intelligent but has been developing programs for...</td>\n",
       "      <td id=\"T_415cc_row1_col3\" class=\"data row1 col3\" >grug brain developer not very big brain, but many years program develop and learn some things, still mostly confused feeling</td>\n",
       "      <td id=\"T_415cc_row1_col4\" class=\"data row1 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_415cc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_415cc_row2_col0\" class=\"data row2 col0\" >(note: grug once think big brained but learn hard way)</td>\n",
       "      <td id=\"T_415cc_row2_col1\" class=\"data row2 col1\" >Grug once thought he was very intelligent, but then he learned the hard way that he was not.</td>\n",
       "      <td id=\"T_415cc_row2_col2\" class=\"data row2 col2\" >realize that Grug's intelligence is not as high as he thought. We...</td>\n",
       "      <td id=\"T_415cc_row2_col3\" class=\"data row2 col3\" >grug think big brain once, but then learn hard way not big brain</td>\n",
       "      <td id=\"T_415cc_row2_col4\" class=\"data row2 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_415cc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_415cc_row3_col0\" class=\"data row3 col0\" >THINK they are big brained developers many, many more, and more even definitely probably maybe not like this, many\n",
       "sour face (such is internet)</td>\n",
       "      <td id=\"T_415cc_row3_col1\" class=\"data row3 col1\" >Grug believes there are many developers who think they are very intelligent, and even more than that, but in reality, there may not be many...</td>\n",
       "      <td id=\"T_415cc_row3_col2\" class=\"data row3 col2\" >produce the grug_text. We will simplify the idea of developers thinking they are smart and the reality of it, along with the negativity of the...</td>\n",
       "      <td id=\"T_415cc_row3_col3\" class=\"data row3 col3\" >grug think many developers big brain, even more than that, but maybe not many like that. internet negative place.</td>\n",
       "      <td id=\"T_415cc_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_415cc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_415cc_row4_col0\" class=\"data row4 col0\" >is free country sort of and end of day not really matter too much, but grug hope you fun reading and maybe learn from many,...</td>\n",
       "      <td id=\"T_415cc_row4_col1\" class=\"data row4 col1\" >This is a free country of sorts and in the end of the day, it doesn't really matter too much. But Grug hopes you have...</td>\n",
       "      <td id=\"T_415cc_row4_col2\" class=\"data row4 col2\" >produce the grug_text. We will simplify the idea of a free country and the importance of having fun and learning from mistakes in Grug language.</td>\n",
       "      <td id=\"T_415cc_row4_col3\" class=\"data row4 col3\" >free country kind of, end of day not matter much. grug hope fun read and maybe learn from many, many mistake grug make long programming...</td>\n",
       "      <td id=\"T_415cc_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12f06c850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 1 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for metric in individual_metrics:\n",
    "    evaluate = Evaluate(metric=metric, devset=train, num_threads=1, display_progress=True, display_table=5)\n",
    "    evaluate(optimized_cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b1a68-09bf-4998-bcd7-d176d3ae3fe6",
   "metadata": {},
   "source": [
    "Follow along for subsequent tutorials on:\n",
    "\n",
    "1. Automatically optimizing prompts\n",
    "2. Customizing input to DSPy\n",
    "3. Saving prompts to use in LangChain or LlamaIndex\n",
    "4. Tuning and using open source models\n",
    "\n",
    "Cheers,\n",
    "[Bill](https://twitter.com/bllchmbrs)\n",
    "\n",
    "[Learn By Building AI](https://learnbybuilding.ai/?ref=dspy-tutorial)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21b95b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='produce the grug_text. We need to simplify the idea of not building complex systems into Grug language.',\n",
       "    grug_text='no build complex systems'\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_cot.forward(\"You should not construct complex systems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe984271",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
