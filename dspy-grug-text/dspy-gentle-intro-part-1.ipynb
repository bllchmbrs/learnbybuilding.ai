{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e36400",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to [DSPy](https://dspy-docs.vercel.app/)\n",
    "For grug brained developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a58f9",
   "metadata": {},
   "source": [
    "If you would rather *read* this, you can find it on [LearnByBuilding.AI](https://learnbybuilding.ai/tutorials/). This notebook only contains code, to get some prose along with it, check out the tutorial posted there.\n",
    "\n",
    "If you like this content, [follow me on twitter](https://twitter.com/bllchmbrs) for more! I'm posting all week about DSPy and providing a lot of \"hard earned\" lessons that I've gotten from learning the material.\n",
    "\n",
    "### [Check out my Youtube for the full video tutorial](https://www.youtube.com/@LearnByBuildingAI) that accompanies this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf1881-96a5-4ccb-a252-637a74d310f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cfd1b-eb5b-4311-83fa-855ed2a5e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30f1e4-b3af-4044-b2ba-a2f6f86b10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res = requests.get(\"https://grugbrain.dev/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b25187",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "raw_text = [p.text for p in soup.find_all('p') if p.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b18c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e62629-ce0a-4302-88c9-4eb3af35cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "openai_model_name= \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildMessages:\n",
    "    def __init__(self, system_prompt, user_prompt):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.user_prompt = user_prompt\n",
    "\n",
    "    def render(self, **kwargs):\n",
    "        sys = self.system_prompt.format(**kwargs)\n",
    "        user = self.user_prompt.format(**kwargs)\n",
    "\n",
    "        return [\n",
    "            {\"role\":\"system\", \"content\":sys},\n",
    "            {\"role\":\"user\", \"content\":user},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf655143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "@cache\n",
    "def translate_grug(grug_text):\n",
    "    prompt = BuildMessages(\n",
    "    \"You are an expert in deciphering strange text. The user will provide text written by someone named Grug and you will provide the translation.\",\n",
    "    \"Translate the following text into plain english: {text}. Do not respond with any other text. Only provide that text. Now take a deep breath and begin.\"\n",
    ")\n",
    "    result = client.chat.completions.create(messages=prompt.render(text=grug_text), model=openai_model_name)\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc25a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_grug(raw_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for grug_text in raw_text[:10]:\n",
    "    translated = translate_grug(grug_text)\n",
    "    dataset.append({\"grug_text\":grug_text, \"plain_english\":translated})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e71018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0985f0",
   "metadata": {},
   "source": [
    "# Building a Dataset\n",
    "\n",
    "\n",
    "Or, more simply, using `dspy.Example`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ede8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for row in dataset:\n",
    "    examples.append(dspy.Example(grug_text=row[\"grug_text\"], plain_english=row[\"plain_english\"]).with_inputs(\"plain_english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e019eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_for_train_test(values, test_size = 1/3.0):\n",
    "    np.random.shuffle(values)\n",
    "    train = int(len(values)-test_size*len(values))\n",
    "    print(train)\n",
    "    return values[:train], values[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03c608-dcce-4c06-aa94-a244bbcfe797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_for_train_test(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f549811",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4298e0-657c-4341-b8e3-616ba791e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo', max_tokens=1000)\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c18c2",
   "metadata": {},
   "source": [
    "# Prompts... I mean Signatures\n",
    "\n",
    "Note, not really optimized for chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrugTranslation(dspy.Signature):\n",
    "    \"Translate plain english to Grug text.\"\n",
    "    plain_english = dspy.InputField()\n",
    "    grug_text = dspy.OutputField()\n",
    "    # grug_text = dspy.OutputField(prefix=\"The Grug Text:\", format=lambda x: \"===\" + str(x) + \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba27d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "GrugTranslation.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GrugTranslation.with_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/stanfordnlp/dspy/blob/1c10a9d476737533a53d6bee62c234e375eb8fcb/dsp/templates/template_v3.py#L22\n",
    "from dspy.signatures.signature import signature_to_template\n",
    "grug_translation_as_template = signature_to_template(GrugTranslation)\n",
    "print(str(grug_translation_as_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grug_translation_as_template.query(examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef642d30",
   "metadata": {},
   "source": [
    "# Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8dfa2-189b-4e74-8605-327781ffef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(GrugTranslation)\n",
    "    \n",
    "    def forward(self, plain_english):\n",
    "        return self.prog(plain_english=plain_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CoT()\n",
    "c.forward(\"You should not construct complex systems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba779a",
   "metadata": {},
   "source": [
    "# Making it better, options\n",
    "\n",
    "\n",
    "1. Zero shot (no examples)\n",
    "2. Providing examples (few shot)\n",
    "3. Tuning the prompt + examples\n",
    "4. Fine tuning the model\n",
    "5. Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad4745",
   "metadata": {},
   "source": [
    "# Better examples\n",
    "\n",
    "But, what is better? How are you measuring that?\n",
    "\n",
    "Vibes to something measurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://apps.dtic.mil/sti/tr/pdf/AD0667273.pdf\n",
    "def automated_readability_index(text):\n",
    "    import re\n",
    "\n",
    "    # Count characters (ignoring whitespace)\n",
    "    characters = len(re.sub(r'\\s+', '', text))\n",
    "\n",
    "    # Count words by splitting the text\n",
    "    words = len(text.split())\n",
    "\n",
    "    # Count sentences by finding period, exclamation, or question mark\n",
    "    sentences = len(re.findall(r'[.!?\\n]', text))\n",
    "    # our change is to add a new line character as grug doesn't seem to use punctuation.\n",
    "\n",
    "    # Calculate the Automated Readability Index (ARI)\n",
    "    if words == 0 or sentences == 0:  # Prevent division by zero\n",
    "        return 0\n",
    "    \n",
    "    ari = (4.71 * (characters / words)) + (0.5 * (words / sentences)) - 21.43\n",
    "    \n",
    "    return round(ari, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in examples:\n",
    "    source_ari = automated_readability_index(ex.plain_english)\n",
    "    grug_ari = automated_readability_index(ex.grug_text)\n",
    "    print(f\"ARI {source_ari} => {grug_ari}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ea280",
   "metadata": {},
   "source": [
    "## First Metric: Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d154917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ari_metric(truth, pred, trace=None):\n",
    "    truth_grug_text = truth.grug_text\n",
    "    proposed_grug_text = pred.grug_text\n",
    "    \n",
    "    gold_ari = automated_readability_index(truth_grug_text)\n",
    "    pred_ari = automated_readability_index(proposed_grug_text)\n",
    "\n",
    "    print(f\"ARI {gold_ari} => {pred_ari}\")\n",
    "\n",
    "    ari_result = pred_ari <= 7.01\n",
    "    return ari_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbac35c",
   "metadata": {},
   "source": [
    "## Second Metric: Use a better Model to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4T = dspy.OpenAI(model='gpt-4-turbo', max_tokens=100, model_type='chat')\n",
    "\n",
    "# https://dspy-docs.vercel.app/docs/building-blocks/metrics#intermediate-using-ai-feedback-for-your-metric\n",
    "class AssessBasedOnQuestion(dspy.Signature):\n",
    "    \"\"\"Given the assessed text provide a yes or no to the assessment question.\"\"\"\n",
    "\n",
    "    assessed_text = dspy.InputField(format=str)\n",
    "    assessment_question = dspy.InputField(format=str)\n",
    "    assessment_answer = dspy.OutputField(desc=\"Yes or No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36979c76",
   "metadata": {},
   "source": [
    "Again, this is just a prompt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_question_assessment = dspy.Example(assessed_text=\"This is a test.\", assessment_question=\"Is this a test?\", assessment_answer=\"Yes\").with_inputs(\"assessed_text\", \"assessment_question\")\n",
    "print(signature_to_template(AssessBasedOnQuestion).query(example_question_assessment))\n",
    "# one note, it's technically, I believe, a `Prediction` object. But Predictions mirror example functionality:\n",
    "# https://dspy-docs.vercel.app/docs/deep-dive/signature/executing-signatures#how-predict-works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_metric(truth, pred, trace=None):\n",
    "    truth_grug_text = truth.grug_text\n",
    "    proposed_grug_text = pred.grug_text\n",
    "    similarity_question = f\"\"\"Does the assessed text have the same meaning as the gold_standard text provided?\n",
    "\n",
    "Gold Standard: \"{truth_grug_text}\"\n",
    "\n",
    "Provide only a yes or no answer.\"\"\"\n",
    "\n",
    "    with dspy.context(lm=gpt4T):\n",
    "        assessor = dspy.Predict(AssessBasedOnQuestion)\n",
    "        raw_similarity_result = assessor(assessed_text=proposed_grug_text, assessment_question=similarity_question)\n",
    "    print(raw_similarity_result)\n",
    "    raw_similarity = raw_similarity_result.assessment_answer.lower().strip()\n",
    "    same_meaning = raw_similarity == 'yes'\n",
    "    return same_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b4b14-8bc5-4ade-9ea8-f9d378c25afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_metric(provided_example, predicted, trace=None):\n",
    "    similarity = similarity_metric(provided_example, predicted, trace)\n",
    "    ari = ari_metric(provided_example, predicted, trace)\n",
    "\n",
    "    if similarity and ari:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c75c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "config = dict(max_bootstrapped_demos=4, max_labeled_demos=4)\n",
    "teleprompter = BootstrapFewShot(metric=overall_metric, **config)\n",
    "teleprompter.max_errors = 1\n",
    "optimized_cot = teleprompter.compile(CoT(), trainset=train, valset=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "individual_metrics = [similarity_metric, ari_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c591bb-81d5-48c9-8b66-c501507cabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in individual_metrics:\n",
    "    evaluate = Evaluate(metric=metric, devset=train, num_threads=1, display_progress=True, display_table=5)\n",
    "    evaluate(optimized_cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b1a68-09bf-4998-bcd7-d176d3ae3fe6",
   "metadata": {},
   "source": [
    "Follow along for subsequent tutorials on:\n",
    "\n",
    "1. Automatically optimizing prompts\n",
    "2. Customizing input to DSPy\n",
    "3. Saving prompts to use in LangChain or LlamaIndex\n",
    "4. Tuning and using open source models\n",
    "\n",
    "Cheers,\n",
    "[Bill](https://twitter.com/bllchmbrs)\n",
    "\n",
    "[Learn By Building AI](https://learnbybuilding.ai/?ref=dspy-tutorial)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b95b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cot.forward(\"You should not construct complex systems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe984271",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
